{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('/content/data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop columns that have the same value across all rows\n",
    "def remove_infrequent_categories(data, threshold=0.05):\n",
    "    filtered_data = data.copy()\n",
    "    categorical_columns = filtered_data.select_dtypes(include='object').columns\n",
    "    categorical_columns = [column for column in categorical_columns if column.endswith('_mut')]\n",
    "\n",
    "    for column in categorical_columns:\n",
    "        filtered_data = filtered_data.loc[filtered_data[column].isin(filtered_data[column].value_counts().index[filtered_data[column].value_counts()/len(filtered_data) > threshold])]\n",
    "    return filtered_data\n",
    "\n",
    "def drop_single_class_columns(df):\n",
    "    unique_value_counts = df.nunique()\n",
    "    single_value_columns = unique_value_counts[unique_value_counts == 1].index\n",
    "    return df.drop(columns=single_value_columns)\n",
    "\n",
    "# Function to one-hot encode specified categorical columns\n",
    "def one_hot_encode_columns(df, columns, encoder, isTrain):\n",
    "    if isTrain:\n",
    "        encoder = OneHotEncoder(sparse_output=False)\n",
    "        encoded_data = encoder.fit_transform(df[columns])\n",
    "    else:\n",
    "        encoded_data = encoder.transform(df[columns])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(columns))\n",
    "    return df.drop(columns, axis=1).join(encoded_df), encoder\n",
    "\n",
    "# Main preprocessing function\n",
    "def data_preprocess(df, encoder=None, isTrain=True):\n",
    "    df = df.drop(['patient_id', 'cohort'], axis=1)\n",
    "    df = drop_single_class_columns(df)\n",
    "    \n",
    "    # Fill missing values for numerical columns\n",
    "    numerical_columns = ['neoplasm_histologic_grade', 'mutation_count', 'tumor_size', 'tumor_stage']\n",
    "    df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "\n",
    "    # Identify and fill missing values for all other numerical columns just in case\n",
    "    other_numerical_columns = df.select_dtypes(include=[np.number]).columns.difference(numerical_columns)\n",
    "    df[other_numerical_columns] = df[other_numerical_columns].fillna(df[other_numerical_columns].median())\n",
    "\n",
    "    # Handle missing values and encode categorical variables\n",
    "    categorical_columns = ['pr_status', 'pam50_+_claudin-low_subtype', 'primary_tumor_laterality', 'inferred_menopausal_state', 'her2_status', 'er_status', 'er_status_measured_by_ihc', '3-gene_classifier_subtype', 'death_from_cancer']\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    # Ensure all other categorical columns are also filled with the most frequent value\n",
    "    other_categorical_columns = df.select_dtypes(include=['object', 'category']).columns.difference(categorical_columns)\n",
    "    for column in other_categorical_columns:\n",
    "        df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    if isTrain:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoded_data = encoder.fit_transform(df[categorical_columns])\n",
    "    else:\n",
    "        encoded_data = encoder.transform(df[categorical_columns])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "    df = df.drop(categorical_columns, axis=1).join(encoded_df)\n",
    "\n",
    "    # Handling 'cellularity' with predefined mapping and filling NaNs\n",
    "    if 'cellularity' in df.columns:\n",
    "        df['cellularity'] = df['cellularity'].str.strip()  # Strip whitespace\n",
    "        mapping = {\n",
    "            'Low': 1,\n",
    "            'Moderate': 2,\n",
    "            'High': 3,\n",
    "        }\n",
    "        df['cellularity'] = df['cellularity'].map(mapping).fillna(3)  # Filling NaNs with 'High' assumed as 3\n",
    "\n",
    "    # Handling 'her2_status_measured_by_snp6' with predefined mapping and dropping rows with 'UNDEF'\n",
    "    if 'her2_status_measured_by_snp6' in df.columns:\n",
    "        df = df[df['her2_status_measured_by_snp6'] != 'UNDEF']\n",
    "        df['her2_status_measured_by_snp6'] = df['her2_status_measured_by_snp6'].str.strip()\n",
    "        her2_mapping = {\n",
    "            'LOSS': -1,\n",
    "            'NEUTRAL': 0,\n",
    "            'GAIN': 1,\n",
    "        }\n",
    "        df['her2_status_measured_by_snp6'] = df['her2_status_measured_by_snp6'].map(her2_mapping)\n",
    "\n",
    "    # Label encoding for the target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = df.pop(\"cancer_type\")\n",
    "    y_encoded = label_encoder.fit_transform(y) if isTrain else label_encoder.transform(y)\n",
    "    y_binary = (y_encoded == 0).astype(int)\n",
    "\n",
    "    return df, y_encoded, y_binary, label_encoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X, y, y_binary, label_encoder, encoder = data_preprocess(data, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validate, test sets\n",
    "X_train, X_temp, y_train, y_temp, y_train_binary, y_temp_binary = train_test_split(X, y, y_binary, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train binary classification model\n",
    "# Split the training data for binary classification\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_train, y_train_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Random Over Sampler to the training data\n",
    "ros = RandomOverSampler(random_state=23)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train_binary, y_train_binary)\n",
    "\n",
    "# Adjusting the scale_pos_weight parameter for XGBoost based on class distribution\n",
    "scale_pos_weight = sum(y_train_ros == 0) / sum(y_train_ros == 1)\n",
    "\n",
    "# Convert all columns of type 'object' to 'category' \n",
    "categorical_columns = X_train_ros.select_dtypes(include=['object']).columns\n",
    "X_train_ros[categorical_columns] = X_train_ros[categorical_columns].astype('category')\n",
    "X_test_binary[categorical_columns] = X_test_binary[categorical_columns].astype('category')\n",
    "\n",
    "# Create DMatrix for train and test sets\n",
    "dtrain_binary = xgb.DMatrix(X_train_ros, label=y_train_ros, enable_categorical=True)\n",
    "dtest_binary = xgb.DMatrix(X_test_binary, label=y_test_binary, enable_categorical=True)\n",
    "\n",
    "# Specify parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'rmse',\n",
    "    'num_class': 1,\n",
    "    'device':'cuda',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.1,\n",
    "    'lambda': 1,\n",
    "    'alpha': 0.01,\n",
    "    'scale_pos_weight': scale_pos_weight,  # Applying class weight\n",
    "    'num_parallel_tree':5,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "binary_model = xgb.train(params, dtrain_binary, num_boost_round=100)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_binary = binary_model.predict(dtest_binary)\n",
    "y_pred_binary = np.round(y_pred_binary)  # Convert probabilities to binary output\n",
    "\n",
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(\"Binary Model Accuracy:\", accuracy_score(y_test_binary, y_pred_binary))\n",
    "print(\"Binary Model Confusion Matrix:\\n\", confusion_matrix(y_test_binary, y_pred_binary))\n",
    "print(\"Binary Model Classification Report:\\n\", classification_report(y_test_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and train multi-class model\n",
    "# Filter and prepare multiclass datasets\n",
    "X_multiclass = X[y != 0]\n",
    "y_multiclass = y[y != 0]\n",
    "\n",
    "# Split the data\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multiclass, y_multiclass, test_size=0.2, random_state=42)\n",
    "\n",
    "# Re-apply LabelEncoder to the split data\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_multi = label_encoder.fit_transform(y_train_multi)\n",
    "y_test_multi = label_encoder.transform(y_test_multi)\n",
    "\n",
    "# Convert these columns to 'category' in both training and testing datasets\n",
    "object_columns = X_train_multi.select_dtypes(include=['object']).columns\n",
    "X_train_multi[object_columns] = X_train_multi[object_columns].astype('category')\n",
    "X_test_multi[object_columns] = X_test_multi[object_columns].astype('category')\n",
    "\n",
    "# Create DMatrix\n",
    "dtrain_multi = xgb.DMatrix(X_train_multi, label=y_train_multi, enable_categorical=True)\n",
    "dtest_multi = xgb.DMatrix(X_test_multi, label=y_test_multi, enable_categorical=True)\n",
    "\n",
    "# Specify parameters\n",
    "params_multi = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'eval_metric': 'rmse',\n",
    "    'objective': 'multi:softmax',\n",
    "    'device':'cuda',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 15,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.1,\n",
    "    'lambda': 1.5,\n",
    "    'alpha': 0.01,\n",
    "    'num_parallel_tree':5\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "multi_class_model = xgb.train(params_multi, dtrain_multi, num_boost_round=100)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_multi = multi_class_model.predict(dtest_multi)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Multi-Class Model Accuracy:\", accuracy_score(y_test_multi, y_pred_multi))\n",
    "print(\"Multi-Class Model Confusion Matrix:\\n\", confusion_matrix(y_test_multi, y_pred_multi))\n",
    "print(\"Multi-Class Model Classification Report:\\n\", classification_report(y_test_multi, y_pred_multi))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
